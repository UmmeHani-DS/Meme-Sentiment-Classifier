{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bdd4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.io import imread,imshow\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3b541",
   "metadata": {},
   "source": [
    "# Text dataset from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7030376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\S H K\\Downloads\\project\\labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db18f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_corrected\"][4799]='im gonna build some fancy walls ven though i have millions of extra dollars in gonna make the mexicans pay for it'\n",
    "df[\"text_corrected\"][6781]='if donald and hillary are together on a boat in the middle of the ocean and it sinks who survives america'\n",
    "df[\"text_corrected\"][6784]='bruh whi this tub of margarine look like Donald Trump'\n",
    "df[\"text_corrected\"][6786]='2016 election trump vs hillary still a better love story than twilight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c39e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILLING NAN VALUES WITH NONE\n",
    "t = \"none\"\n",
    "df.fillna(t, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c4aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(df)\n",
    "for i in range(length):\n",
    "    if t in df[\"text_corrected\"][i]:\n",
    "        df[\"text_corrected\"][i] = df[\"text_ocr\"][i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15e5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  normalize(df, col, new_col):\n",
    "    df[new_col] = df[col].str.lower()\n",
    "    df[new_col] = df[new_col].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df[new_col] = df[new_col].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    \n",
    "    return df\n",
    "data_clean = normalize(df, 'text_corrected', 'text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61953b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "325780bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: word_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc61a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: word_lemmatizer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3573e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       very_positive\n",
       "1       very_positive\n",
       "2            positive\n",
       "3            positive\n",
       "4             neutral\n",
       "            ...      \n",
       "6987          neutral\n",
       "6988          neutral\n",
       "6989         positive\n",
       "6990    very_positive\n",
       "6991         positive\n",
       "Name: overall_sentiment, Length: 6992, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = data_clean[\"overall_sentiment\"]\n",
    "data_clean.pop(\"overall_sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7655f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.insert(5, \"overall_sentiment\",var, True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69243166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging classes \n",
    "for x in range(len(data_clean)):\n",
    "    if data_clean['overall_sentiment'][x]=='very_positive':\n",
    "        data_clean['overall_sentiment'][x]='positive'\n",
    "    elif data_clean['overall_sentiment'][x]=='very_negative':\n",
    "        data_clean['overall_sentiment'][x]='negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd51ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'neutral', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean['overall_sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "977a5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "order  ={\"positive\" : 1, \"neutral\" : 0, \"negative\" : -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d14f5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean[\"overall_sentiment\"] = data_clean[\"overall_sentiment\"].map(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "192beab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>[look, friend, lightyear, sohalikut, trend, pl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>[best, yearchallenge, completed, le, year, kud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>[sam, thorne, follow, follow, saw, everyone, p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>[year, challenge, sweet, dee, edition]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>[year, challenge, filter, hilarious, year, cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>6987</td>\n",
       "      <td>image_6988.jpg</td>\n",
       "      <td>Tuesday is Mardi Gras Wednesday is Valentine's...</td>\n",
       "      <td>Tuesday is Mardi Gras Wednesday is Valentine's...</td>\n",
       "      <td>[tuesday, mardi, gras, wednesday, valentine, f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>6988</td>\n",
       "      <td>image_6989.jpg</td>\n",
       "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...</td>\n",
       "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...</td>\n",
       "      <td>[must, watch, movie, iti, chennai, meme, maana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>6989</td>\n",
       "      <td>image_6990.png</td>\n",
       "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...</td>\n",
       "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...</td>\n",
       "      <td>[le, talking, planning, soda, junk, food, comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>6990</td>\n",
       "      <td>image_6991.jpg</td>\n",
       "      <td>When I VERY have time is a fantasy No one has ...</td>\n",
       "      <td>When I have time is a fantasy. no one has time...</td>\n",
       "      <td>[time, fantasy, one, time, unless, make, time,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>6991</td>\n",
       "      <td>image_6992.jpg</td>\n",
       "      <td>The starting point for every good idea is \"Wha...</td>\n",
       "      <td>The starting point for every good idea is \"Wha...</td>\n",
       "      <td>[starting, point, every, good, idea, arhtistic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6992 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      image_name  \\\n",
       "0              0     image_1.jpg   \n",
       "1              1    image_2.jpeg   \n",
       "2              2     image_3.JPG   \n",
       "3              3     image_4.png   \n",
       "4              4     image_5.png   \n",
       "...          ...             ...   \n",
       "6987        6987  image_6988.jpg   \n",
       "6988        6988  image_6989.jpg   \n",
       "6989        6989  image_6990.png   \n",
       "6990        6990  image_6991.jpg   \n",
       "6991        6991  image_6992.jpg   \n",
       "\n",
       "                                               text_ocr  \\\n",
       "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1     The best of #10 YearChallenge! Completed in le...   \n",
       "2     Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3                 10 Year Challenge - Sweet Dee Edition   \n",
       "4     10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "...                                                 ...   \n",
       "6987  Tuesday is Mardi Gras Wednesday is Valentine's...   \n",
       "6988  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...   \n",
       "6989  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...   \n",
       "6990  When I VERY have time is a fantasy No one has ...   \n",
       "6991  The starting point for every good idea is \"Wha...   \n",
       "\n",
       "                                         text_corrected  \\\n",
       "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1     The best of #10 YearChallenge! Completed in le...   \n",
       "2     Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3                 10 Year Challenge - Sweet Dee Edition   \n",
       "4     10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "...                                                 ...   \n",
       "6987  Tuesday is Mardi Gras Wednesday is Valentine's...   \n",
       "6988  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...   \n",
       "6989  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...   \n",
       "6990  When I have time is a fantasy. no one has time...   \n",
       "6991  The starting point for every good idea is \"Wha...   \n",
       "\n",
       "                                             text_clean  overall_sentiment  \n",
       "0     [look, friend, lightyear, sohalikut, trend, pl...                  1  \n",
       "1     [best, yearchallenge, completed, le, year, kud...                  1  \n",
       "2     [sam, thorne, follow, follow, saw, everyone, p...                  1  \n",
       "3                [year, challenge, sweet, dee, edition]                  1  \n",
       "4     [year, challenge, filter, hilarious, year, cha...                  0  \n",
       "...                                                 ...                ...  \n",
       "6987  [tuesday, mardi, gras, wednesday, valentine, f...                  0  \n",
       "6988  [must, watch, movie, iti, chennai, meme, maana...                  0  \n",
       "6989  [le, talking, planning, soda, junk, food, comp...                  1  \n",
       "6990  [time, fantasy, one, time, unless, make, time,...                  1  \n",
       "6991  [starting, point, every, good, idea, arhtistic...                  1  \n",
       "\n",
       "[6992 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66689ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = data_clean[\"overall_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a77b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(data_clean['text_clean'])\n",
    "j = 0\n",
    "for i in range(0,m):\n",
    "    data_clean['text_clean'][j] = TreebankWordDetokenizer().detokenize( data_clean['text_clean'].iloc[j])\n",
    "    j+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47cd7da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>look friend lightyear sohalikut trend play yea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>image_10.png</td>\n",
       "      <td>FACEBOOK '10 YEAR CHALLENGE': A PLOY OR A SIMP...</td>\n",
       "      <td>FACEBOOK '10 YEAR CHALLENGE': A PLOY OR A SIMP...</td>\n",
       "      <td>facebook year challenge ploy simple meme mo ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>image_100.jpg</td>\n",
       "      <td>Drink water you may not meme generator.com</td>\n",
       "      <td>Drink water you may not meme-generator.com</td>\n",
       "      <td>drink water may memegeneratorcom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>image_1000.png</td>\n",
       "      <td>RT @BehindScenesPic: Martin Scorsese and Leona...</td>\n",
       "      <td>RT @BehindScenesPic: Martin Scorsese and Leona...</td>\n",
       "      <td>martin scorsese leonardo dicaprio set departed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>image_1001.png</td>\n",
       "      <td>Russian Leonardo DiCaprio omg</td>\n",
       "      <td>Russian Leonardo DiCaprio omg</td>\n",
       "      <td>russian leonardo dicaprio omg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>994</td>\n",
       "      <td>994</td>\n",
       "      <td>image_995.jpeg</td>\n",
       "      <td>DON'T LET YOUR DREAMS BE DREAMS! NOTHING IS IM...</td>\n",
       "      <td>DON'T LET YOUR DREAMS BE DREAMS! NOTHING IS IM...</td>\n",
       "      <td>dont let dream dream nothing impossible clp co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>image_996.jpg</td>\n",
       "      <td>A TOAST TO THE MEMORY OF MY WORKOUT... CUZ I'M...</td>\n",
       "      <td>A TOAST TO THE MEMORY OF MY WORKOUT... CUZ I'M...</td>\n",
       "      <td>toast memory workout cuz im murder cffy imgfli...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>image_997.jpg</td>\n",
       "      <td>RARE PICTURE OF LEONARDO DICAPRIO HOLDINGOSCAR...</td>\n",
       "      <td>RARE PICTURE OF LEONARDO DICAPRIO HOLDINGOSCAR...</td>\n",
       "      <td>rare picture leonardo dicaprio holdingoscar st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>image_998.jpg</td>\n",
       "      <td>RIP WORLD'S LONGEST MEME 415 STARECAT.COM</td>\n",
       "      <td>RIP WORLD'S LONGEST MEME STARECAT.COM</td>\n",
       "      <td>rip world longest meme starecatcom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>image_999.png</td>\n",
       "      <td>R.I.P. to the greatest meme of all time. The f...</td>\n",
       "      <td>R.I.P. to the greatest meme of all time. The f...</td>\n",
       "      <td>rip greatest meme time father meme meme daily ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6992 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Unnamed: 0      image_name  \\\n",
       "0         0           0     image_1.jpg   \n",
       "1         9           9    image_10.png   \n",
       "2        99          99   image_100.jpg   \n",
       "3       999         999  image_1000.png   \n",
       "4      1000        1000  image_1001.png   \n",
       "...     ...         ...             ...   \n",
       "6987    994         994  image_995.jpeg   \n",
       "6988    995         995   image_996.jpg   \n",
       "6989    996         996   image_997.jpg   \n",
       "6990    997         997   image_998.jpg   \n",
       "6991    998         998   image_999.png   \n",
       "\n",
       "                                               text_ocr  \\\n",
       "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1     FACEBOOK '10 YEAR CHALLENGE': A PLOY OR A SIMP...   \n",
       "2            Drink water you may not meme generator.com   \n",
       "3     RT @BehindScenesPic: Martin Scorsese and Leona...   \n",
       "4                         Russian Leonardo DiCaprio omg   \n",
       "...                                                 ...   \n",
       "6987  DON'T LET YOUR DREAMS BE DREAMS! NOTHING IS IM...   \n",
       "6988  A TOAST TO THE MEMORY OF MY WORKOUT... CUZ I'M...   \n",
       "6989  RARE PICTURE OF LEONARDO DICAPRIO HOLDINGOSCAR...   \n",
       "6990          RIP WORLD'S LONGEST MEME 415 STARECAT.COM   \n",
       "6991  R.I.P. to the greatest meme of all time. The f...   \n",
       "\n",
       "                                         text_corrected  \\\n",
       "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1     FACEBOOK '10 YEAR CHALLENGE': A PLOY OR A SIMP...   \n",
       "2            Drink water you may not meme-generator.com   \n",
       "3     RT @BehindScenesPic: Martin Scorsese and Leona...   \n",
       "4                         Russian Leonardo DiCaprio omg   \n",
       "...                                                 ...   \n",
       "6987  DON'T LET YOUR DREAMS BE DREAMS! NOTHING IS IM...   \n",
       "6988  A TOAST TO THE MEMORY OF MY WORKOUT... CUZ I'M...   \n",
       "6989  RARE PICTURE OF LEONARDO DICAPRIO HOLDINGOSCAR...   \n",
       "6990              RIP WORLD'S LONGEST MEME STARECAT.COM   \n",
       "6991  R.I.P. to the greatest meme of all time. The f...   \n",
       "\n",
       "                                             text_clean  overall_sentiment  \n",
       "0     look friend lightyear sohalikut trend play yea...                  1  \n",
       "1     facebook year challenge ploy simple meme mo ex...                  1  \n",
       "2                      drink water may memegeneratorcom                  0  \n",
       "3        martin scorsese leonardo dicaprio set departed                  0  \n",
       "4                         russian leonardo dicaprio omg                  1  \n",
       "...                                                 ...                ...  \n",
       "6987  dont let dream dream nothing impossible clp co...                  1  \n",
       "6988  toast memory workout cuz im murder cffy imgfli...                 -1  \n",
       "6989  rare picture leonardo dicaprio holdingoscar st...                  1  \n",
       "6990                 rip world longest meme starecatcom                  1  \n",
       "6991  rip greatest meme time father meme meme daily ...                  0  \n",
       "\n",
       "[6992 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data_clean.sort_values(\"image_name\", axis = 0, ascending = True)\n",
    "data_clean = data_clean.reset_index()\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "216f6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(max_df = 0.5)\n",
    "tfidf = tf.fit_transform(data_clean[\"text_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a73a2a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf ,vals, test_size = 0.3, random_state = 104, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830fc295",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa8ebc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.15      0.02      0.03       161\n",
      "           0       0.27      0.08      0.13       666\n",
      "           1       0.60      0.88      0.71      1271\n",
      "\n",
      "    accuracy                           0.56      2098\n",
      "   macro avg       0.34      0.33      0.29      2098\n",
      "weighted avg       0.46      0.56      0.48      2098\n",
      "\n",
      "Accuracy: 56.29170638703527\n",
      "F1-Score: 29.129994730109583\n",
      "F1-Score macro: 29.129994730109583\n"
     ]
    }
   ],
   "source": [
    "text_classifier = RandomForestClassifier()\n",
    "text_classifier.fit(X_train,y_train)\n",
    "Predict = text_classifier.predict(X_test)\n",
    "pickle.dump(text_classifier, open(\"rfc.pkl\" , \"wb\"))\n",
    "print(\"Confusion matrix\", classification_report(y_test,Predict ))\n",
    "print(\"Accuracy:\", metrics.accuracy_score (y_test, Predict)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(y_test, Predict,average=None).mean()*100)\n",
    "print(\"F1-Score macro:\", metrics.f1_score(y_test, Predict,average='macro')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61073ff0",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be81ec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.07      0.06      0.06       161\n",
      "           0       0.33      0.28      0.30       666\n",
      "           1       0.61      0.67      0.64      1271\n",
      "\n",
      "    accuracy                           0.50      2098\n",
      "   macro avg       0.33      0.33      0.33      2098\n",
      "weighted avg       0.48      0.50      0.49      2098\n",
      "\n",
      "Accuracy: 49.85700667302193\n",
      "F1-Score: 33.32389324302662\n",
      "F1-Score macro: 33.32389324302662\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "pre_y=clf.predict(X_test)\n",
    "pickle.dump(clf, open(\"clf.pkl\" , \"wb\"))\n",
    "print(\"Confusion matrix\", classification_report(y_test,pre_y))\n",
    "print('Accuracy:', accuracy_score(y_test,pre_y)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(y_test, pre_y,average = None).mean()*100) \n",
    "print(\"F1-Score macro:\", metrics.f1_score(y_test,pre_y,average = 'macro')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f972c",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "492a24cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.04      0.01      0.01       161\n",
      "           0       0.31      0.29      0.30       666\n",
      "           1       0.60      0.69      0.64      1271\n",
      "\n",
      "    accuracy                           0.51      2098\n",
      "   macro avg       0.32      0.33      0.32      2098\n",
      "weighted avg       0.47      0.51      0.49      2098\n",
      "\n",
      "Accuracy: 51.04861773117254\n",
      "F1-Score: 31.866446931800297\n",
      "F1-Score Macro: 31.866446931800297\n"
     ]
    }
   ],
   "source": [
    "KNC = KNeighborsClassifier()\n",
    "KNC.fit(X_train, y_train)\n",
    "pr = KNC.predict(X_test)\n",
    "pickle.dump(KNC, open(\"knn.pkl\" , \"wb\"))\n",
    "print(\"Confusion matrix\", classification_report(y_test,pr ))\n",
    "print(\"Accuracy:\", metrics.accuracy_score (y_test, pr)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(y_test, pr,average=None).mean()*100)\n",
    "print(\"F1-Score Macro:\", metrics.f1_score(y_test, pr,average='macro')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751fb2b",
   "metadata": {},
   "source": [
    "# IMAGES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eb16840",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\S H K\\Downloads\\project\\images\\\\\"\n",
    "get = os.listdir(path)\n",
    "imgs=[]\n",
    "k = 0\n",
    "for n in get:\n",
    "    var = skimage.transform.resize(imread(path + n, as_gray = True),(100,100))\n",
    "    imgs.append(var)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "560a5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframe = {'Name' : get, 'Images' : imgs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d83d9176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>[[0.4128766205400558, 0.41224572579398944, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_10.png</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_100.jpg</td>\n",
       "      <td>[[0.116763438293343, 0.11306334238026056, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_1000.png</td>\n",
       "      <td>[[0.2846914682299253, 0.2868378261296744, 0.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_1001.png</td>\n",
       "      <td>[[0.9715638862606675, 0.9714675096530226, 0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>image_995.jpeg</td>\n",
       "      <td>[[0.5911205309299019, 0.5926397697532422, 0.59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>image_996.jpg</td>\n",
       "      <td>[[0.3494892657358355, 0.42102657341101696, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>image_997.jpg</td>\n",
       "      <td>[[0.8424193718350534, 0.8754715828880489, 0.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>image_998.jpg</td>\n",
       "      <td>[[0.9999996032786497, 0.9999955080211308, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>image_999.png</td>\n",
       "      <td>[[0.9802129666174798, 0.9802129803531339, 0.98...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                             Images\n",
       "0        image_1.jpg  [[0.4128766205400558, 0.41224572579398944, 0.4...\n",
       "1       image_10.png  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...\n",
       "2      image_100.jpg  [[0.116763438293343, 0.11306334238026056, 0.10...\n",
       "3     image_1000.png  [[0.2846914682299253, 0.2868378261296744, 0.28...\n",
       "4     image_1001.png  [[0.9715638862606675, 0.9714675096530226, 0.97...\n",
       "...              ...                                                ...\n",
       "6987  image_995.jpeg  [[0.5911205309299019, 0.5926397697532422, 0.59...\n",
       "6988   image_996.jpg  [[0.3494892657358355, 0.42102657341101696, 0.4...\n",
       "6989   image_997.jpg  [[0.8424193718350534, 0.8754715828880489, 0.64...\n",
       "6990   image_998.jpg  [[0.9999996032786497, 0.9999955080211308, 0.99...\n",
       "6991   image_999.png  [[0.9802129666174798, 0.9802129803531339, 0.98...\n",
       "\n",
       "[6992 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(Dataframe)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "717f2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Flatten']=0\n",
    "df1['Flatten'][0]=np.array([1,2], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c22e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    x = np.array(df1['Images'][i])\n",
    "    df1['Flatten'][i]=x.flatten()\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dd1d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.sort_values('Name', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70ecf7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['labels'] = data_clean['overall_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56afac1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Images</th>\n",
       "      <th>Flatten</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>[[0.4128766205400558, 0.41224572579398944, 0.4...</td>\n",
       "      <td>[0.4128766205400558, 0.41224572579398944, 0.41...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_10.png</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_100.jpg</td>\n",
       "      <td>[[0.116763438293343, 0.11306334238026056, 0.10...</td>\n",
       "      <td>[0.116763438293343, 0.11306334238026056, 0.108...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_1000.png</td>\n",
       "      <td>[[0.2846914682299253, 0.2868378261296744, 0.28...</td>\n",
       "      <td>[0.2846914682299253, 0.2868378261296744, 0.283...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_1001.png</td>\n",
       "      <td>[[0.9715638862606675, 0.9714675096530226, 0.97...</td>\n",
       "      <td>[0.9715638862606675, 0.9714675096530226, 0.971...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>image_995.jpeg</td>\n",
       "      <td>[[0.5911205309299019, 0.5926397697532422, 0.59...</td>\n",
       "      <td>[0.5911205309299019, 0.5926397697532422, 0.598...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>image_996.jpg</td>\n",
       "      <td>[[0.3494892657358355, 0.42102657341101696, 0.4...</td>\n",
       "      <td>[0.3494892657358355, 0.42102657341101696, 0.45...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>image_997.jpg</td>\n",
       "      <td>[[0.8424193718350534, 0.8754715828880489, 0.64...</td>\n",
       "      <td>[0.8424193718350534, 0.8754715828880489, 0.645...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>image_998.jpg</td>\n",
       "      <td>[[0.9999996032786497, 0.9999955080211308, 0.99...</td>\n",
       "      <td>[0.9999996032786497, 0.9999955080211308, 0.999...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>image_999.png</td>\n",
       "      <td>[[0.9802129666174798, 0.9802129803531339, 0.98...</td>\n",
       "      <td>[0.9802129666174798, 0.9802129803531339, 0.980...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6992 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                             Images  \\\n",
       "0        image_1.jpg  [[0.4128766205400558, 0.41224572579398944, 0.4...   \n",
       "1       image_10.png  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...   \n",
       "2      image_100.jpg  [[0.116763438293343, 0.11306334238026056, 0.10...   \n",
       "3     image_1000.png  [[0.2846914682299253, 0.2868378261296744, 0.28...   \n",
       "4     image_1001.png  [[0.9715638862606675, 0.9714675096530226, 0.97...   \n",
       "...              ...                                                ...   \n",
       "6987  image_995.jpeg  [[0.5911205309299019, 0.5926397697532422, 0.59...   \n",
       "6988   image_996.jpg  [[0.3494892657358355, 0.42102657341101696, 0.4...   \n",
       "6989   image_997.jpg  [[0.8424193718350534, 0.8754715828880489, 0.64...   \n",
       "6990   image_998.jpg  [[0.9999996032786497, 0.9999955080211308, 0.99...   \n",
       "6991   image_999.png  [[0.9802129666174798, 0.9802129803531339, 0.98...   \n",
       "\n",
       "                                                Flatten  labels  \n",
       "0     [0.4128766205400558, 0.41224572579398944, 0.41...       1  \n",
       "1     [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...       1  \n",
       "2     [0.116763438293343, 0.11306334238026056, 0.108...       0  \n",
       "3     [0.2846914682299253, 0.2868378261296744, 0.283...       0  \n",
       "4     [0.9715638862606675, 0.9714675096530226, 0.971...       1  \n",
       "...                                                 ...     ...  \n",
       "6987  [0.5911205309299019, 0.5926397697532422, 0.598...       1  \n",
       "6988  [0.3494892657358355, 0.42102657341101696, 0.45...      -1  \n",
       "6989  [0.8424193718350534, 0.8754715828880489, 0.645...       1  \n",
       "6990  [0.9999996032786497, 0.9999955080211308, 0.999...       1  \n",
       "6991  [0.9802129666174798, 0.9802129803531339, 0.980...       0  \n",
       "\n",
       "[6992 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc17cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecddad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_img = le.fit_transform(df2['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfff0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img = df2['Flatten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1705127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_img ,y_img, test_size = 0.3, random_state = 104, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3f9e7",
   "metadata": {},
   "source": [
    "# SVC CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "799c751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.14      0.11       184\n",
      "           1       0.35      0.33      0.34       698\n",
      "           2       0.58      0.56      0.57      1216\n",
      "\n",
      "    accuracy                           0.44      2098\n",
      "   macro avg       0.34      0.34      0.34      2098\n",
      "weighted avg       0.46      0.44      0.45      2098\n",
      "\n",
      "Accuracy: 44.37559580552908\n",
      "F1-Score: 33.963260465894734\n",
      "F1-Score macro: 33.963260465894734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(list(X1_train), list(y1_train))\n",
    "pred_y = svclassifier.predict(list(X1_test))\n",
    "pickle.dump(svclassifier, open(\"svc.pkl\" , \"wb\"))\n",
    "print(\"Confusion matrix\", classification_report(list(y1_test),pred_y ))\n",
    "print(\"Accuracy:\", metrics.accuracy_score (list(y1_test), pred_y)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(list(y1_test), pred_y,average=None).mean()*100)\n",
    "print(\"F1-Score macro:\", metrics.f1_score(list(y1_test), pred_y,average='macro')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47be2b5",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "199bc9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.06      0.08       184\n",
      "           1       0.34      0.27      0.30       698\n",
      "           2       0.58      0.68      0.62      1216\n",
      "\n",
      "    accuracy                           0.49      2098\n",
      "   macro avg       0.34      0.34      0.33      2098\n",
      "weighted avg       0.46      0.49      0.47      2098\n",
      "\n",
      "Accuracy: 48.80838894184938\n",
      "F1-Score: 33.287198224238765\n",
      "F1-Score macro: 33.287198224238765\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='sag').fit(list(X1_train),list(y1_train))\n",
    "pred2 = lr.predict(list(X1_test))\n",
    "pickle.dump(lr, open(\"lr.pkl\" , \"wb\"))\n",
    "print(\"Confusion matrix\", classification_report(list(y1_test),list(pred2)))\n",
    "print('Accuracy:', accuracy_score(list(y1_test),pred2)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(list(y1_test), pred2,average=None).mean()*100) \n",
    "print(\"F1-Score macro:\", metrics.f1_score(list(y1_test), pred2,average='macro')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd633e",
   "metadata": {},
   "source": [
    "# GAUSSIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54a208ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.39      0.15       184\n",
      "           1       0.31      0.21      0.25       698\n",
      "           2       0.57      0.41      0.48      1216\n",
      "\n",
      "    accuracy                           0.34      2098\n",
      "   macro avg       0.33      0.34      0.29      2098\n",
      "weighted avg       0.44      0.34      0.37      2098\n",
      "\n",
      "Accuracy: 34.0324118207817\n",
      "F1-Score: 29.29722071190934\n",
      "F1-Score macro: 29.29722071190934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(list(X1_train), list(y1_train))\n",
    "Pred_e= nb.predict(list(X1_test))\n",
    "print(\"Confusion matrix\", classification_report(list(y1_test),Pred_e ))\n",
    "print(\"Accuracy:\", metrics.accuracy_score (list(y1_test), Pred_e)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(list(y1_test), Pred_e,average=None).mean()*100)\n",
    "print(\"F1-Score macro:\", metrics.f1_score(list(y1_test), Pred_e,average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdea4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b726c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diction = {\"RFC\" : Predict , \"DT\" : pre_y, \"KNN\" : pr, \"SVC\" : pred_y , \"LR\" : pr , \"GAUS\" : pred_e}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a249b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RFC</th>\n",
       "      <th>DT</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LR</th>\n",
       "      <th>GAUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RFC  DT  KNN  SVC  LR  GAUS\n",
       "0    1  -1    1    1   2     2\n",
       "1    1   1    1    1   1     2\n",
       "2    1   1    1    2   2     2\n",
       "3    1   0    0    2   2     2\n",
       "4    1   0    0    2   2     2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame(diction)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f33d53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = df4.mode(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2499daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = new_prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b0dd581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       2.0\n",
       "4       2.0\n",
       "       ... \n",
       "2093    1.0\n",
       "2094    1.0\n",
       "2095    2.0\n",
       "2096    0.0\n",
       "2097    1.0\n",
       "Name: 0, Length: 2098, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9fb6a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         0\n",
      "         0.0       0.08      0.09      0.08       184\n",
      "         1.0       0.33      0.63      0.43       698\n",
      "         2.0       0.58      0.26      0.36      1216\n",
      "\n",
      "    accuracy                           0.37      2098\n",
      "   macro avg       0.25      0.24      0.22      2098\n",
      "weighted avg       0.45      0.37      0.36      2098\n",
      "\n",
      "Accuracy: 36.98760724499523\n",
      "F1-Score: 21.956433460958348\n",
      "F1-Score macro: 21.956433460958348\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\", classification_report(y1_test,new_prediction))\n",
    "print(\"Accuracy:\", metrics.accuracy_score (y1_test, new_prediction)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(y1_test, new_prediction,average=None).mean()*100)\n",
    "print(\"F1-Score macro:\", metrics.f1_score(y1_test, new_prediction,average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "922778e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vote = VotingClassifier(estimators = [(\"RFC\" , text_classifier) , (\"DT\" , clf), (\"KNN\" , KNC), (\"SVC\" ,svclassifier) , (\"LR\" , lr) , (\"GAUS\" , nb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ec4066c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.07      0.07       184\n",
      "           1       0.35      0.18      0.23       698\n",
      "           2       0.58      0.77      0.66      1216\n",
      "\n",
      "    accuracy                           0.51      2098\n",
      "   macro avg       0.34      0.34      0.32      2098\n",
      "weighted avg       0.46      0.51      0.47      2098\n",
      "\n",
      "Accuracy: 51.00095328884652\n",
      "F1-Score: 32.3659884666753\n",
      "F1-Score macro: 32.3659884666753\n"
     ]
    }
   ],
   "source": [
    "vote.fit(list(X1_train), list(y1_train))\n",
    "pred_v= vote.predict(list(X1_test))\n",
    "print(\"Confusion matrix\", classification_report(list(y1_test),pred_v ))\n",
    "print(\"Accuracy:\", metrics.accuracy_score (list(y1_test), pred_v)*100)\n",
    "print(\"F1-Score:\", metrics.f1_score(list(y1_test), pred_v,average=None).mean()*100)\n",
    "print(\"F1-Score macro:\", metrics.f1_score(list(y1_test), pred_v,average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da3b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
